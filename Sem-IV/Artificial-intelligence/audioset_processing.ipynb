{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audioset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"audioset_v1_embeddings/eval/\"\n",
    "\n",
    "dataset = []\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.endswith(\".tfrecord\"):\n",
    "        dataset.append(os.path.join(directory, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of distinguishable sounds\n",
    "class_labels = pd.read_csv(\"class_labels_indices.csv\")\n",
    "labels = class_labels[\"display_name\"].tolist()\n",
    "\n",
    "# TODO: Include music genre labels that do not contain the word 'music'\n",
    "# Create a list for music-genre-specific labels\n",
    "music_class = class_labels[class_labels[\"display_name\"].str.contains(\"Music\", case=False)]\n",
    "music_labels = music_class[\"index\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 22:01:02.443229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4062]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100th file...\n",
      "Processing 200th file...\n",
      "Processing 300th file...\n",
      "Processing 400th file...\n",
      "Processing 500th file...\n",
      "Processing 600th file...\n",
      "Processing 700th file...\n",
      "Processing 800th file...\n",
      "Processing 900th file...\n",
      "Processing 1000th file...\n",
      "Processing 1100th file...\n",
      "Processing 1200th file...\n",
      "Processing 1300th file...\n",
      "Processing 1400th file...\n",
      "Processing 1500th file...\n",
      "Processing 1600th file...\n",
      "Processing 1700th file...\n",
      "Processing 1800th file...\n",
      "Processing 1900th file...\n",
      "Processing 2000th file...\n",
      "Processing 2100th file...\n",
      "Processing 2200th file...\n",
      "Processing 2300th file...\n",
      "Processing 2400th file...\n",
      "Processing 2500th file...\n",
      "Processing 2600th file...\n",
      "Processing 2700th file...\n",
      "Processing 2800th file...\n",
      "Processing 2900th file...\n",
      "Processing 3000th file...\n",
      "Processing 3100th file...\n",
      "Processing 3200th file...\n",
      "Processing 3300th file...\n",
      "Processing 3400th file...\n",
      "Processing 3500th file...\n",
      "Processing 3600th file...\n",
      "Processing 3700th file...\n",
      "Processing 3800th file...\n",
      "Processing 3900th file...\n",
      "Processing 4000th file...\n",
      "Processing 4100th file...\n",
      "Processing 4200th file...\n",
      "Processing 4300th file...\n",
      "Processing 4400th file...\n",
      "Processing 4500th file...\n",
      "Processing 4600th file...\n",
      "Processing 4700th file...\n",
      "Processing 4800th file...\n",
      "Processing 4900th file...\n",
      "Processing 5000th file...\n",
      "Processing 5100th file...\n",
      "Processing 5200th file...\n",
      "Processing 5300th file...\n",
      "Processing 5400th file...\n",
      "Processing 5500th file...\n",
      "Processing 5600th file...\n",
      "Processing 5700th file...\n",
      "Processing 5800th file...\n"
     ]
    }
   ],
   "source": [
    "audios = []\n",
    "counter = 0\n",
    "NUM_SECONDS = 10\n",
    "\n",
    "for raw_record in raw_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "    # Audio Meta Data\n",
    "    audio_labels = example.context.feature[\"labels\"].int64_list.value\n",
    "    start_time = example.context.feature[\"start_time_seconds\"].float_list.value\n",
    "    end_time = example.context.feature[\"end_time_seconds\"].float_list.value\n",
    "    video_id = example.context.feature[\"video_id\"].bytes_list.value\n",
    "\n",
    "    if not (set(music_labels) & set(audio_labels)):\n",
    "        continue\n",
    "\n",
    "    # Audio Feature\n",
    "    feature_list = example.feature_lists.feature_list[\"audio_embedding\"].feature\n",
    "    final_features = [list(feature.bytes_list.value[0]) for feature in feature_list]\n",
    "    audio_embedding = [item for sublist in final_features[:NUM_SECONDS] for item in sublist]\n",
    "\n",
    "    if len(final_features) < NUM_SECONDS:\n",
    "        continue\n",
    "\n",
    "    audio = {\n",
    "        \"label\": audio_labels,\n",
    "        \"video_id\": video_id,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"data\": audio_embedding\n",
    "    }\n",
    "\n",
    "    audios.append(audio)\n",
    "    counter += 1\n",
    "    if (counter % 100 == 0):\n",
    "        print(f\"Processing {counter}th file...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a JSON file\n",
    "with open(\"music_set.json\", \"w\") as file:\n",
    "    str_audio = repr(audios)\n",
    "    json.dump(str_audio, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[162,\n",
       "  117,\n",
       "  221,\n",
       "  134,\n",
       "  205,\n",
       "  60,\n",
       "  121,\n",
       "  142,\n",
       "  88,\n",
       "  161,\n",
       "  63,\n",
       "  0,\n",
       "  42,\n",
       "  240,\n",
       "  93,\n",
       "  151,\n",
       "  152,\n",
       "  69,\n",
       "  249,\n",
       "  0],\n",
       " [77,\n",
       "  142,\n",
       "  153,\n",
       "  58,\n",
       "  223,\n",
       "  76,\n",
       "  200,\n",
       "  139,\n",
       "  203,\n",
       "  122,\n",
       "  157,\n",
       "  112,\n",
       "  207,\n",
       "  126,\n",
       "  208,\n",
       "  15,\n",
       "  216,\n",
       "  95,\n",
       "  125,\n",
       "  67],\n",
       " [176,\n",
       "  64,\n",
       "  84,\n",
       "  130,\n",
       "  82,\n",
       "  183,\n",
       "  36,\n",
       "  70,\n",
       "  220,\n",
       "  238,\n",
       "  193,\n",
       "  0,\n",
       "  255,\n",
       "  179,\n",
       "  203,\n",
       "  255,\n",
       "  255,\n",
       "  255,\n",
       "  0,\n",
       "  192]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[audio[\"data\"][:10] + audio[\"data\"][-10:] for audio in audios[:3]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
